{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42e2eddd",
   "metadata": {},
   "source": [
    "# ETL Process for Streaming Viewership Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256e020d",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "**Purpose:**\n",
    "\n",
    "Clean and transform the raw streaming viewership dataset into structured tables suitable for analysis.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f463481",
   "metadata": {},
   "source": [
    "## Extract\n",
    "\n",
    "### Step 1: Load the Raw Data\n",
    "\n",
    "**Files:**\n",
    "\n",
    "- **Streaming Viewership Data**: Load `streaming_viewership_data.csv` to extract and analyze session-level and user-level information.\n",
    "\n",
    "**Description:**\n",
    "\n",
    "The dataset contains raw information on users, sessions, videos, devices, and locations. We will load this data into a Pandas DataFrame for initial processing and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cc94b1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Overview:\n",
      "                                User_ID                            Session_ID  \\\n",
      "0  eb4f9229-74df-45f6-baac-cf19241b8b30  cb2142a7-0750-49ed-b8ac-a975fe1ff69a   \n",
      "1  661d4b59-4328-410a-901c-1e3b4c40c334  3bc0a662-b353-4015-8b0c-55ceb510d13a   \n",
      "2  dd3fe9e9-ea82-4891-ab93-8a47c80e3251  bd545b4a-9f54-4e87-b9f8-15ae20b44f22   \n",
      "3  a1b3365b-1d00-4ddf-bc43-02fc9c10c680  0441086d-c59e-478d-a496-5c5b995ecfdb   \n",
      "4  338d3f91-5f1c-4590-8803-324901826406  0295f01d-7f15-4799-856c-90c688697ef8   \n",
      "\n",
      "   Device_ID  Video_ID  Duration_Watched (minutes)        Genre  \\\n",
      "0        232        11                   90.044525       Sci-Fi   \n",
      "1        549        85                   68.973479       Comedy   \n",
      "2        844        50                   42.511343       Comedy   \n",
      "3        201        38                   53.316660  Documentary   \n",
      "4        700        31                   69.437786       Action   \n",
      "\n",
      "                            Country  Age  Gender Subscription_Status  Ratings  \\\n",
      "0                             Sudan   56  Female             Premium        3   \n",
      "1                              Cuba   52    Male             Premium        3   \n",
      "2                             Japan   14  Female             Premium        3   \n",
      "3  Lao People's Democratic Republic   36    Male             Premium        2   \n",
      "4                        Bangladesh   31    Male             Premium        4   \n",
      "\n",
      "  Languages Device_Type          Location Playback_Quality  Interaction_Events  \n",
      "0   Spanish  Smartphone         Reedshire               4K                  73  \n",
      "1   Chinese     Desktop       Stevenhaven               SD                  22  \n",
      "2   Spanish      Tablet        Vaughntown               HD                  41  \n",
      "3   Spanish      Laptop  East Raymondbury               SD                  40  \n",
      "4    German      Laptop    Michaelchester               HD                  41  \n",
      "Dataset contains 6214 rows and 16 columns.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the raw dataset\n",
    "file_path = '/Users/joshuastewart/Documents/Streaming Viewership EDA Project/Data/streaming_viewership_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display data overview\n",
    "print(\"Data Overview:\")\n",
    "print(data.head())\n",
    "print(f\"Dataset contains {data.shape[0]} rows and {data.shape[1]} columns.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2435955c",
   "metadata": {},
   "source": [
    "---\n",
    "## Transform\n",
    "\n",
    "### Step 2: Check for Duplicates and Missing Data\n",
    "\n",
    "**Files:**\n",
    "\n",
    "- **Streaming Viewership Data**: Process `streaming_viewership_data.csv` to identify and remove duplicate rows and handle missing values.\n",
    "\n",
    "**Description:**\n",
    "\n",
    "This step ensures the dataset’s integrity by eliminating redundant rows and addressing null or incomplete data, preparing it for transformation into relational tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ebdea16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n",
      "Missing values in each column:\n",
      "User_ID                       0\n",
      "Session_ID                    0\n",
      "Device_ID                     0\n",
      "Video_ID                      0\n",
      "Duration_Watched (minutes)    0\n",
      "Genre                         0\n",
      "Country                       0\n",
      "Age                           0\n",
      "Gender                        0\n",
      "Subscription_Status           0\n",
      "Ratings                       0\n",
      "Languages                     0\n",
      "Device_Type                   0\n",
      "Location                      0\n",
      "Playback_Quality              0\n",
      "Interaction_Events            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check for duplicate rows\n",
    "duplicates = data.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\")\n",
    "\n",
    "# Remove duplicates if found\n",
    "if duplicates > 0:\n",
    "    data = data.drop_duplicates()\n",
    "    print(\"Duplicates removed.\")\n",
    "\n",
    "# Check for missing values\n",
    "missing = data.isnull().sum()\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594347ec",
   "metadata": {},
   "source": [
    "### Step 3: Transform Data into Relational Tables\n",
    "\n",
    "**Files:**\n",
    "\n",
    "- **Users Table**: Extract unique user-level information such as demographics and subscription status.\n",
    "- **Sessions Table**: Extract session-level data, including playback details and interactions.\n",
    "- **Videos Table**: Extract video-specific details such as genre and language.\n",
    "- **Devices Table**: Extract information about device types.\n",
    "- **Locations Table**: Extract unique mappings of locations and countries.\n",
    "\n",
    "**Description:**\n",
    "\n",
    "Split the cleaned dataset into five structured tables—Users, Sessions, Videos, Devices, and Locations—to organize the data logically and support relational queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8329286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users Table: 6214 rows\n",
      "Sessions Table: 6214 rows\n",
      "Videos Table: 2618 rows\n",
      "Devices Table: 3563 rows\n",
      "Locations Table: 6207 rows\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Users Table\n",
    "users = data[['User_ID', 'Country', 'Age', 'Gender', 'Subscription_Status']].drop_duplicates()\n",
    "print(f\"Users Table: {users.shape[0]} rows\")\n",
    "\n",
    "# Sessions Table\n",
    "sessions = data[['Session_ID', 'User_ID', 'Device_ID', 'Video_ID', \n",
    "                 'Duration_Watched (minutes)', 'Playback_Quality', \n",
    "                 'Interaction_Events', 'Ratings']].drop_duplicates()\n",
    "print(f\"Sessions Table: {sessions.shape[0]} rows\")\n",
    "\n",
    "# Videos Table\n",
    "videos = data[['Video_ID', 'Genre', 'Languages']].drop_duplicates()\n",
    "print(f\"Videos Table: {videos.shape[0]} rows\")\n",
    "\n",
    "# Devices Table\n",
    "devices = data[['Device_ID', 'Device_Type']].drop_duplicates()\n",
    "print(f\"Devices Table: {devices.shape[0]} rows\")\n",
    "\n",
    "# Locations Table\n",
    "locations = data[['Location', 'Country']].drop_duplicates()\n",
    "print(f\"Locations Table: {locations.shape[0]} rows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705bdd8b",
   "metadata": {},
   "source": [
    "---\n",
    "## Load\n",
    "\n",
    "### Step 4: Save the Cleaned Tables to CSV\n",
    "\n",
    "**Files:**\n",
    "\n",
    "- Save `users_table.csv`, `sessions_table.csv`, `videos_table.csv`, `devices_table.csv`, and `locations_table.csv` to the `cleaned_data` folder for future use.\n",
    "\n",
    "**Description:**\n",
    "\n",
    "Export each relational table as a separate CSV file to streamline future analysis and maintain data organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43829a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to 'cleaned_data' folder.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "# Create folder for cleaned data if it doesn't exist\n",
    "output_dir = '/Users/joshuastewart/Documents/Streaming Viewership EDA Project/Data/cleaned_data'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "users.to_csv(f'{output_dir}/users_table.csv', index=False)\n",
    "sessions.to_csv(f'{output_dir}/sessions_table.csv', index=False)\n",
    "videos.to_csv(f'{output_dir}/videos_table.csv', index=False)\n",
    "devices.to_csv(f'{output_dir}/devices_table.csv', index=False)\n",
    "locations.to_csv(f'{output_dir}/locations_table.csv', index=False)\n",
    "\n",
    "print(\"Cleaned data saved to 'cleaned_data' folder.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
